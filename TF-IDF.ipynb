{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag-of-Objects TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import json\n",
    "\n",
    "from dataloader import he_sampling\n",
    "from data import FlickrDataset, CocoDataset, VGDataset\n",
    "from PIL import Image\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = VGDataset(sg_path=None)\n",
    "ds = VGDataset(sg_path='/data/project/rw/CBIR/data/vg_coco/sgg_grcnn/vgcoco_sgg_grcnn_with_adj.pkl')\n",
    "# ds = FlickrDataset(sg_path=None)\n",
    "# ds = CocoDataset(sg_path=None)\n",
    "# ds = VGDataset(sg_path='/data/project/rw/CBIR/data/vg_coco/vg_coco_gt_sg.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_file = '/data/project/rw/CBIR/data/f30k/butd_freq_prior_LR/glove_embs_f30k_sgg_butd_freq_prior_LR.pkl'\n",
    "vocab2idx_file = '/data/project/rw/CBIR/data/f30k/butd_freq_prior_LR/vocab2idx_f30k_sgg_butd_freq_prior_LR.pkl'\n",
    "idx2vocab_file = '/data/project/rw/CBIR/data/f30k/butd_freq_prior_LR/idx2vocab_f30k_sgg_butd_freq_prior_LR.pkl'\n",
    "scene_graph_path = '/data/project/rw/CBIR/data/f30k/butd_freq_prior_LR/f30k_sgg_butd_freq_prior_LR_with_adj.pkl'\n",
    "ds = FlickrDataset(vocab_emb=emb_file, vocab2idx=vocab2idx_file, idx2vocab=idx2vocab_file, sg_path=scene_graph_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['node_labels', 'adj', 'filename', 'imgid', 'bboxes', 'width', 'height'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.sg[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''visual genome'''\n",
    "# l_train_terms = []\n",
    "# for img_id in ds.d_split['train']:\n",
    "#     sg = ds.imgid2sg(img_id)\n",
    "#     l_train_terms.append(sg['obj_labels'])\n",
    "    \n",
    "# l_test_terms = []\n",
    "# for img_id in ds.d_split['test']:\n",
    "#     sg = ds.imgid2sg(img_id)\n",
    "#     l_test_terms.append(sg['obj_labels'])    \n",
    "\n",
    "'''f30k and coco'''\n",
    "l_train_terms = []\n",
    "for img_id in ds.d_split['train']:\n",
    "    sg = ds.imgid2sg(img_id)\n",
    "    l_row = []\n",
    "    for i, word in enumerate(sg['node_labels']):\n",
    "        if i < len(sg['bboxes']):\n",
    "            l_row.append(word)\n",
    "    l_train_terms.append(l_row)\n",
    "    \n",
    "l_test_terms = []\n",
    "for img_id in ds.d_split['test']:\n",
    "    sg = ds.imgid2sg(img_id)\n",
    "    l_row = []\n",
    "    for i, word in enumerate(sg['node_labels']):\n",
    "        if i < len(sg['bboxes']):\n",
    "            l_row.append(word)\n",
    "    l_test_terms.append(l_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''GT scene graph'''    \n",
    "gen_scene_graph = '/data/project/rw/CBIR/vg_generated_sg_adj_full_butd_freq_train.pkl'   \n",
    "gen_sg = pickle.load(open(gen_scene_graph, 'rb'))\n",
    "# full scene graph\n",
    "sg = json.load(open('/data/public/rw/datasets/visual_genome/filtered_scene_graphs_coco.json', 'r'))\n",
    "id2sg = {int(sg_['image_id']): sg_  for sg_ in sg}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''GT Scene Graph VG-COCO'''\n",
    "  \n",
    "'''load scene graph and add triplet features'''\n",
    "\n",
    "\n",
    "l_train_terms = []\n",
    "for img_id in ds.d_split['train']:\n",
    "    sg_ = id2sg[img_id]\n",
    "    l_row = []\n",
    "    l_obj = [obj['names'][0] for obj in sg_['objects']]\n",
    "    for i, word in enumerate(l_obj):\n",
    "        l_row.append(word)\n",
    "    l_train_terms.append(l_row)\n",
    "    \n",
    "l_test_terms = []\n",
    "for img_id in ds.d_split['test']:\n",
    "    sg_ = id2sg[img_id]\n",
    "    l_row = []\n",
    "    l_obj = [obj['names'][0] for obj in sg_['objects']]\n",
    "    for i, word in enumerate(l_obj):\n",
    "        l_row.append(word)\n",
    "    l_test_terms.append(l_row)    \n",
    "    \n",
    "# l_test_terms = []\n",
    "# for img_id in ds.d_split['test']:\n",
    "#     sg = ds.imgid2sg(img_id)\n",
    "#     l_row = []\n",
    "#     for i, word in enumerate(sg['node_labels']):\n",
    "#         if i < len(sg['bboxes']):\n",
    "#             l_row.append(word)\n",
    "#     l_test_terms.append(l_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_test = ds.d_split['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vocab = set([t for d in l_train_terms for t in d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vocab = set([t for d in l_test_terms for t in d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = train_vocab.union(test_vocab)\n",
    "vocab2idx = {v:i for i, v in enumerate(sorted(list(vocab)))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mat = np.zeros((len(l_train_terms), len(vocab)))\n",
    "test_mat = np.zeros((len(l_test_terms), len(vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48387"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24484"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_d, d in enumerate(l_train_terms):\n",
    "    for t in d:\n",
    "        idx = vocab2idx[t]\n",
    "        train_mat[i_d, idx] += 1\n",
    "        \n",
    "for i_d, d in enumerate(l_test_terms):\n",
    "    for t in d:\n",
    "        idx = vocab2idx[t]\n",
    "        test_mat[i_d, idx] += 1        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfTransformer(use_idf=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.fit(train_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tfidf = tfidf.transform(test_mat).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_mat = test_tfidf.dot(test_tfidf.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.mkdir('/data/project/rw/viewer_CBIR/viewer/vg_coco_results/boo_tf')\n",
    "# os.mkdir('/data/project/rw/viewer_CBIR/viewer/vg_coco_results/grcnn_boo_tfidf')\n",
    "# os.mkdir('/data/project/rw/viewer_CBIR/viewer/vg_coco_results/grcnn_boo_tfidf')\n",
    "# os.mkdir('/data/project/rw/viewer_CBIR/viewer/f30k_results/butd_boo_tfidf')\n",
    "# os.mkdir('/data/project/rw/viewer_CBIR/viewer/f30k_results/butd_boo_tf')\n",
    "os.mkdir('/data/project/rw/viewer_CBIR/viewer/vg_coco_results/gt_boo_tf')\n",
    "# os.mkdir('/data/project/rw/viewer_CBIR/viewer/coco_results/boo_tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13203/13203 [14:21<00:00, 15.32it/s]\n"
     ]
    }
   ],
   "source": [
    "result_dir = '/data/project/rw/viewer_CBIR/viewer/vg_coco_results/gt_boo_tf'\n",
    "for i_query, test_id in enumerate(tqdm(l_test)):  # query id\n",
    "    l_sim = []\n",
    "    for j_target, target_id in enumerate(l_test):\n",
    "        l_sim.append(sim_mat[i_query, j_target])\n",
    "    df = pd.DataFrame({'target_id': l_test, 'sim': l_sim}).sort_values('target_id')\n",
    "\n",
    "    df[['target_id', 'sim']].to_csv(os.path.join(result_dir, f'{test_id}.tsv'), sep='\\t', header=False, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
