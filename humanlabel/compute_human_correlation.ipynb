{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute human-algorithm correlation\n",
    "\n",
    "* 사람실험 결과와 알고리즘 출력 간의 correlation을 계산한다.\n",
    "* 데이터 자체에 대한 분석은 별도의 노트북인 `human_label.ipynb` 를 참고한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_result = pd.read_csv('results_v1_201911141704_final.csv')\n",
    "# df_triplet = pd.read_csv('triplets_v1_201911102026.csv')\n",
    "df_result = pd.read_csv('results_v2_202003050303.csv')\n",
    "df_triplet = pd.read_csv('triplets_v2.csv')\n",
    "df_triplet = df_triplet.set_index('triplet_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id\n",
       "cjhan                    1753\n",
       "epsilon.kim              1618\n",
       "erin122                  1518\n",
       "wookee3                  1239\n",
       "edwin.kang               1029\n",
       ".                        1007\n",
       "woong.ssang               604\n",
       "kloud.on                  407\n",
       "JRW                       190\n",
       "yoomin618                 188\n",
       "hexa.ai                   170\n",
       "yang.kim                  109\n",
       "jason.mun                 100\n",
       "jinhyun.b                  88\n",
       "chico2121                  86\n",
       "IceAmericano               72\n",
       "LSW                        68\n",
       "eunjin                     67\n",
       "hyunji                     46\n",
       "Julyeon Seo                45\n",
       "cnuh                       40\n",
       "yejun                      37\n",
       "Dray.Choe                  35\n",
       "Jinyeong                   35\n",
       "jihoon.lee                 34\n",
       "hihello2                   21\n",
       "robert.p                   20\n",
       "Jonggwon                   14\n",
       "jay.mini                   11\n",
       "eos73                       9\n",
       "sungbin.lim                 8\n",
       "testa                       8\n",
       "motherfathergentleman       7\n",
       "hihello                     6\n",
       "ian.theman                  5\n",
       "junojuno                    5\n",
       "scarlett.heo                3\n",
       "hans                        3\n",
       "dhkwak                      2\n",
       "june.one                    2\n",
       "kwon.g                      2\n",
       "john.dublin                 1\n",
       "Name: id, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''users and the numers of their labels'''\n",
    "df_result.groupby('user_id').count()['id'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.', 'Dray.Choe', 'IceAmericano', 'JRW', 'Jinyeong', 'Jonggwon', 'Julyeon Seo', 'LSW', 'chico2121', 'cjhan', 'cnuh', 'edwin.kang', 'epsilon.kim', 'erin122', 'eunjin', 'hexa.ai', 'hihello2', 'hyunji', 'jason.mun', 'jay.mini', 'jihoon.lee', 'jinhyun.b', 'kloud.on', 'robert.p', 'wookee3', 'woong.ssang', 'yang.kim', 'yejun', 'yoomin618']\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "'''filter users with low answer count (<10)'''\n",
    "filter_count = 10\n",
    "user_count = df_result.groupby('user_id').count()['id']\n",
    "l_filtered_users = (user_count[user_count > filter_count]).index.to_list()\n",
    "print(l_filtered_users)\n",
    "print(len(l_filtered_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1752"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_triplet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Inter-user agreement score for each user\n",
    "\n",
    "### Agreement metric from (Grodo and Larlus, 2017)\n",
    "For each triplet,\n",
    "\n",
    "$o1, o2$: the number of times the first (resp. second) image was chosen.  \n",
    "$o3$: the number of times people did not pick any of the two images.  \n",
    "\n",
    "Agreement score is computed as \n",
    "\n",
    "$$\n",
    "s = (\\frac{o_1+o_2 - 1}{o_1 + o_2 + o_3 - 1}) (\\frac{o_i - 1}{o_1 + o_2 - 1})\n",
    "$$\n",
    "where $o_i$ $i\\in\\{1,2\\}$ is the choice of the user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our agreement metric\n",
    "Let  \n",
    "$o1, o2$ : the number of times the first (resp. second) image was chosen.  \n",
    "$p$ : the number of times both of images were chosen  \n",
    "$q$ : the nubmer of times neither of images were chosen\n",
    "\n",
    "\n",
    "If a person choses the first or the second image,  \n",
    "$$\n",
    "s = \\frac{o_i + 0.5 p - 1}{o_1 + o2 + p + q - 1}\n",
    "$$\n",
    "where $o_i$ $i\\in\\{1,2\\}$ is the choice of the user.\n",
    "\n",
    "If a person choses the \"both\" option,\n",
    "$$\n",
    "s = \\frac{0.5o_1 + 0.5o_2 + p - 1}{o_1 + o_2 + p + q - 1}\n",
    "$$\n",
    "\n",
    "If a person choses the \"neither\" options,\n",
    "$$\n",
    "s = 0\n",
    "% s = \\frac{q - 1}{o_1 + o_2 + p + q - 1}\n",
    "$$\n",
    "\n",
    "Given a person, the score is averaged over the whole triplet which he/she labeled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>answer</th>\n",
       "      <th>o1</th>\n",
       "      <th>o2</th>\n",
       "      <th>both</th>\n",
       "      <th>neither</th>\n",
       "      <th>o3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>triplet_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "answer       o1   o2  both  neither   o3\n",
       "triplet_id                              \n",
       "3           5.0  0.0   1.0      0.0  1.0\n",
       "4           0.0  5.0   0.0      0.0  0.0\n",
       "9           7.0  0.0   0.0      0.0  0.0\n",
       "14          5.0  0.0   0.0      0.0  0.0\n",
       "15          4.0  1.0   1.0      0.0  1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''prepare answer_cnt'''\n",
    "answer_cnt = df_result[['id', 'triplet_id', 'answer']].pivot_table(index='triplet_id', columns='answer', aggfunc='count').fillna(0)\n",
    "answer_cnt.columns = answer_cnt.columns.droplevel(0)\n",
    "answer_cnt = answer_cnt.rename(columns={0:'o1', 1:'o2', 2:'both', 3:'neither'})\n",
    "answer_cnt['o3'] = answer_cnt['both'] + answer_cnt['neither']\n",
    "answer_cnt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "Dray.Choe\n",
      "IceAmericano\n",
      "JRW\n",
      "Jinyeong\n",
      "Jonggwon\n",
      "Julyeon Seo\n",
      "LSW\n",
      "chico2121\n",
      "cjhan\n",
      "cnuh\n",
      "edwin.kang\n",
      "epsilon.kim\n",
      "erin122\n",
      "eunjin\n",
      "hexa.ai\n",
      "hihello2\n",
      "hyunji\n",
      "jason.mun\n",
      "jay.mini\n",
      "jihoon.lee\n",
      "jinhyun.b\n",
      "kloud.on\n",
      "robert.p\n",
      "wookee3\n",
      "woong.ssang\n",
      "yang.kim\n",
      "yejun\n",
      "yoomin618\n",
      "score    0.726913\n",
      "dtype: float64 score    0.050892\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "'''user agreement'''\n",
    "user_agree = {'user': [], 'score': []}\n",
    "# for user in l_users:\n",
    "for user in l_filtered_users:    \n",
    "    print(user)\n",
    "    df_answer_person = df_result[df_result['user_id'] == user].sort_values('triplet_id')\n",
    "    l_score = []\n",
    "    for i, row in df_answer_person.iterrows():\n",
    "        triplet_id = row['triplet_id']\n",
    "        if row['answer'] not in (0, 1, 2):\n",
    "            continue\n",
    "\n",
    "        answer = answer_cnt.loc[triplet_id]\n",
    "        o1, o2, o3, p, q = answer['o1'], answer['o2'], answer['o3'], answer['both'], answer['neither']\n",
    "\n",
    "#         o1, o2 = answer['o1'], answer['o2']\n",
    "#         o3 = len(l_users) - o1 - o2\n",
    "\n",
    "        # requires more than two active votes for the triplet\n",
    "        if o1 + o2 < 2:\n",
    "            continue\n",
    "\n",
    "        if row['answer'] in {0, 1}:\n",
    "            if row['answer'] == 0:\n",
    "                oi = o1\n",
    "            else:\n",
    "                oi = o2\n",
    "            s = (oi + 0.5 * p  - 1) / (o1 + o2 + p + q - 1)\n",
    "        elif row['answer'] == 2:\n",
    "            s = (0.5 * o1 + 0.5 * o2 + p - 1 ) / (o1 + o2 + p + q - 1)\n",
    "        else:\n",
    "            s = 0\n",
    "#             s = (q - 1) / (o1 + o2 + p + 1 - 1)\n",
    "        \n",
    "\n",
    "#         s = (o1 + o2 - 1) / (o1 + o2 + o3 - 1) * (oi - 1) / (o1 + o2 - 1)\n",
    "        \n",
    "\n",
    "        l_score.append(s)\n",
    "    score = np.mean(l_score)\n",
    "    user_agree['user'].append(user)\n",
    "    user_agree['score'].append(score)\n",
    "user_agree = pd.DataFrame(user_agree)    \n",
    "user_agree.head()\n",
    "print(user_agree.mean(), user_agree.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agreement between algorithm and human\n",
    "\n",
    "Let  \n",
    "$o1, o2$ : the number of times the first (resp. second) image was chosen.  \n",
    "$p$ : the number of times \"both\" icon were chosen  \n",
    "$q$ : the nubmer of times \"neither\" icon of images were chosen\n",
    "\n",
    "\n",
    "If an algorithm choses the first or the second image, it recieves the following agreement score  \n",
    "$$\n",
    "s = \\frac{o_i + 0.5 p - 1}{o_1 + o_2 + p + q - 1}\n",
    "$$\n",
    "where $o_i$ $i\\in\\{1,2\\}$ is the choice of the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_similarity_data(algo, df_triplet):\n",
    "    '''pre-fetch similarity scores'''\n",
    "    d_sim = {}\n",
    "    result_path = '/data/project/rw/viewer_CBIR/viewer/vg_coco_results/'\n",
    "    for query_id, by_qid in df_triplet.groupby('query_id'):\n",
    "        l_target_ids = list(by_qid['target_id1']) + list(by_qid['target_id2'])\n",
    "        \n",
    "        data = pd.read_csv(os.path.join(result_path, algo, f'{query_id}.tsv'), delimiter='\\t', header=None)\n",
    "        data = data.rename(columns={0:'id', 1:'sim'}).set_index('id')\n",
    "#         sim = data.loc[[int(s) for s in l_target_ids]].to_dict()['sim']\n",
    "        sim = data.reindex([int(s) for s in l_target_ids]).to_dict()['sim']\n",
    "        d_sim[query_id] = sim\n",
    "    return d_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_result(algo, query_id, l_target_ids):\n",
    "    result_path = '/data/project/rw/viewer_CBIR/viewer/vg_coco_results/'\n",
    "    data = pd.read_csv(os.path.join(result_path, algo, f'{query_id}.tsv'), delimiter='\\t', header=None)\n",
    "    data = data.rename(columns={0:'id', 1:'sim'}).set_index('id')\n",
    "    return data.loc[[int(s) for s in l_target_ids]].to_dict()['sim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.67s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:07<00:00,  3.67s/it]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "# l_algorithms = ['sbert_rerank100', 'vg_gin_big_epoch_24', 'boo_tf', 'vg_gcn_epoch_24', 'resnet', 'gwl_gen_wordonly_rerank', 'gencap_sbert', 'vg_resnet_reg_epoch_257']\n",
    "l_algorithms = ['vg_gcn_noatt_epoch_24', 'vg_gcn_randrel_epoch_24']\n",
    "# l_algorithms = ['gwl_gen_wordonly_rerank']\n",
    "algo_scores = {'triplet_id': list(answer_cnt.index)}\n",
    "d_resnet_sim = read_similarity_data('resnet', df_triplet)\n",
    "for algo in tqdm(l_algorithms):\n",
    "    d_sim_result = read_similarity_data(algo, df_triplet)\n",
    "    l_score = []\n",
    "    for triplet_id, row in answer_cnt.iterrows():\n",
    "        o1, o2, o3, p, q = row['o1'], row['o2'], row['o3'], row['both'], row['neither']\n",
    "\n",
    "        if o1 + o2  < 2:\n",
    "            l_score.append(np.nan)\n",
    "            continue\n",
    "            \n",
    "        # get algorithm's prediction\n",
    "        triplet = df_triplet.loc[triplet_id]\n",
    "        sim1 = d_sim_result[triplet['query_id']][triplet['target_id1']]\n",
    "        sim2 = d_sim_result[triplet['query_id']][triplet['target_id2']]\n",
    "        \n",
    "        # process reranking\n",
    "        if (np.isnan(sim1)) and (np.isnan(sim2)):\n",
    "            sim1 = d_resnet_sim[triplet['query_id']][triplet['target_id1']]\n",
    "            sim2 = d_resnet_sim[triplet['query_id']][triplet['target_id2']]\n",
    "        elif (np.isnan(sim1)) and not (np.isnan(sim2)):\n",
    "            sim1 = - np.inf\n",
    "        elif not (np.isnan(sim1)) and (np.isnan(sim2)):\n",
    "            sim2 = - np.inf\n",
    "        \n",
    "        if sim1 > sim2:\n",
    "            oi = o1\n",
    "        else:\n",
    "            oi = o2\n",
    "        \n",
    "        s = (oi + 0.5 * p ) / (o1 + o2 + p + q )\n",
    "        l_score.append(s)\n",
    "    algo_scores[algo] = l_score\n",
    "algo_scores = pd.DataFrame(algo_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "triplet_id                 4957.963470\n",
       "vg_gcn_noatt_epoch_24         0.605820\n",
       "vg_gcn_randrel_epoch_24       0.603854\n",
       "dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "triplet_id    4995.389622\n",
       "boo_tfidf        0.593685\n",
       "dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "triplet_id                 4995.389622\n",
       "gwl_rerank                    0.580386\n",
       "gwl_gen_wordonly_rerank       0.590975\n",
       "dtype: float64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:04,  2.05it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:03,  2.05it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:01<00:03,  2.04it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:02,  2.04it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:02<00:02,  2.04it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:02<00:01,  2.04it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:03<00:01,  2.04it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:03<00:00,  2.05it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:04<00:00,  2.05it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:04<00:00,  2.04it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "# l_algorithms = ['sbert_rerank100', 'vg_gin_big_epoch_24', 'boo_tf', 'vg_gcn_epoch_24', 'resnet', 'gwl_gen_wordonly_rerank', 'gencap_sbert', 'vg_resnet_reg_epoch_257']\n",
    "# l_algorithms = ['matching_regression_attnode_tail_4_rerank']\n",
    "l_algorithms = [f'random_{i}' for i in range(10)]\n",
    "algo_scores = {'triplet_id': list(answer_cnt.index)}\n",
    "# d_resnet_sim = read_similarity_data('resnet', df_triplet)\n",
    "for algo in tqdm(l_algorithms):\n",
    "#     d_sim_result = read_similarity_data(algo, df_triplet)\n",
    "    l_score = []\n",
    "    for triplet_id, row in answer_cnt.iterrows():\n",
    "        o1, o2, o3, p, q = row['o1'], row['o2'], row['o3'], row['both'], row['neither']\n",
    "\n",
    "        if o1 + o2  < 2:\n",
    "            l_score.append(np.nan)\n",
    "            continue\n",
    "            \n",
    "        # get algorithm's prediction\n",
    "         \n",
    "        # get algorithm's prediction\n",
    "        triplet = df_triplet.loc[triplet_id]\n",
    "        sim1 = np.random.rand()\n",
    "        sim2 = np.random.rand()\n",
    "#         sim1 = d_sim_result[triplet['query_id']][triplet['target_id1']]\n",
    "#         sim2 = d_sim_result[triplet['query_id']][triplet['target_id2']]\n",
    "        \n",
    "        \n",
    "        \n",
    "        if sim1 > sim2:\n",
    "            oi = o1\n",
    "        else:\n",
    "            oi = o2\n",
    "        \n",
    "        s = (oi + 0.5 * p ) / (o1 + o2 + p + q )\n",
    "        l_score.append(s)\n",
    "    algo_scores[algo] = l_score\n",
    "algo_scores = pd.DataFrame(algo_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = algo_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47186033624495216"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.drop('triplet_id').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011238115494062404"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.drop('triplet_id').std()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
