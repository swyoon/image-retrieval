{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute human-algorithm correlation\n",
    "\n",
    "* 사람실험 결과와 알고리즘 출력 간의 correlation을 계산한다.\n",
    "* 데이터 자체에 대한 분석은 별도의 노트북인 `human_label.ipynb` 를 참고한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.read_csv('results_v1_201911141704_final.csv')\n",
    "df_triplet = pd.read_csv('triplets_v1_201911102026.csv')\n",
    "df_triplet = df_triplet.set_index('triplet_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id\n",
       "cjhan                    9017\n",
       "erin122                  4908\n",
       "epsilon.kim              3002\n",
       "wookee3                  2422\n",
       "woong.ssang              2263\n",
       "edwin.kang               1283\n",
       "yoomin618                1075\n",
       "hexa.ai                  1039\n",
       "JRW                      1013\n",
       "chico2121                 519\n",
       "jinhyun.b                 474\n",
       "eunjin                    392\n",
       "IceAmericano              345\n",
       "LSW                       298\n",
       "Julyeon Seo               274\n",
       "Dray.Choe                 255\n",
       "Jinyeong                  251\n",
       "hyunji                    250\n",
       "cnuh                      211\n",
       "jihoon.lee                205\n",
       "yejun                     200\n",
       "robert.p                  136\n",
       "hihello2                  102\n",
       "Jonggwon                   87\n",
       "motherfathergentleman      76\n",
       "eos73                      73\n",
       "jay.mini                   50\n",
       "junojuno                   45\n",
       "sungbin.lim                31\n",
       "ian.theman                 31\n",
       "hans                       28\n",
       "kwon.g                     25\n",
       "scarlett.heo               21\n",
       "dhkwak                     16\n",
       "hihello                    15\n",
       "june.one                    4\n",
       "john.dublin                 3\n",
       "Name: id, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''users and the numers of their labels'''\n",
    "df_result.groupby('user_id').count()['id'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Dray.Choe', 'IceAmericano', 'JRW', 'Jinyeong', 'Jonggwon', 'Julyeon Seo', 'LSW', 'chico2121', 'cjhan', 'cnuh', 'dhkwak', 'edwin.kang', 'eos73', 'epsilon.kim', 'erin122', 'eunjin', 'hans', 'hexa.ai', 'hihello', 'hihello2', 'hyunji', 'ian.theman', 'jay.mini', 'jihoon.lee', 'jinhyun.b', 'junojuno', 'kwon.g', 'motherfathergentleman', 'robert.p', 'scarlett.heo', 'sungbin.lim', 'wookee3', 'woong.ssang', 'yejun', 'yoomin618']\n",
      "35\n"
     ]
    }
   ],
   "source": [
    "'''filter users with low answer count (<10)'''\n",
    "filter_count = 10\n",
    "user_count = df_result.groupby('user_id').count()['id']\n",
    "l_filtered_users = (user_count[user_count > filter_count]).index.to_list()\n",
    "print(l_filtered_users)\n",
    "print(len(l_filtered_users))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Inter-user agreement score for each user\n",
    "\n",
    "### Agreement metric from (Grodo and Larlus, 2017)\n",
    "For each triplet,\n",
    "\n",
    "$o1, o2$: the number of times the first (resp. second) image was chosen.  \n",
    "$o3$: the number of times people did not pick any of the two images.  \n",
    "\n",
    "Agreement score is computed as \n",
    "\n",
    "$$\n",
    "s = (\\frac{o_1+o_2 - 1}{o_1 + o_2 + o_3 - 1}) (\\frac{o_i - 1}{o_1 + o_2 - 1})\n",
    "$$\n",
    "where $o_i$ $i\\in\\{1,2\\}$ is the choice of the user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our agreement metric\n",
    "Let  \n",
    "$o1, o2$ : the number of times the first (resp. second) image was chosen.  \n",
    "$p$ : the number of times both of images were chosen  \n",
    "$q$ : the nubmer of times neither of images were chosen\n",
    "\n",
    "\n",
    "If a person choses the first or the second image,  \n",
    "$$\n",
    "s = \\frac{o_i + 0.5 p - 1}{o_1 + o2 + p + q - 1}\n",
    "$$\n",
    "where $o_i$ $i\\in\\{1,2\\}$ is the choice of the user.\n",
    "\n",
    "If a person choses the \"both\" option,\n",
    "$$\n",
    "s = \\frac{0.5o_1 + 0.5o_2 + p - 1}{o_1 + o_2 + p + q - 1}\n",
    "$$\n",
    "\n",
    "If a person choses the \"neither\" options,\n",
    "$$\n",
    "s = 0\n",
    "% s = \\frac{q - 1}{o_1 + o_2 + p + q - 1}\n",
    "$$\n",
    "\n",
    "Given a person, the score is averaged over the whole triplet which he/she labeled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>answer</th>\n",
       "      <th>o1</th>\n",
       "      <th>o2</th>\n",
       "      <th>both</th>\n",
       "      <th>neither</th>\n",
       "      <th>o3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>triplet_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "answer       o1   o2  both  neither   o3\n",
       "triplet_id                              \n",
       "1           1.0  2.0   0.0      0.0  0.0\n",
       "2           0.0  2.0   2.0      0.0  2.0\n",
       "3           4.0  0.0   1.0      0.0  1.0\n",
       "4           0.0  3.0   0.0      0.0  0.0\n",
       "5           5.0  0.0   0.0      0.0  0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''prepare answer_cnt'''\n",
    "answer_cnt = df_result[['id', 'triplet_id', 'answer']].pivot_table(index='triplet_id', columns='answer', aggfunc='count').fillna(0)\n",
    "answer_cnt.columns = answer_cnt.columns.droplevel(0)\n",
    "answer_cnt = answer_cnt.rename(columns={0:'o1', 1:'o2', 2:'both', 3:'neither'})\n",
    "answer_cnt['o3'] = answer_cnt['both'] + answer_cnt['neither']\n",
    "answer_cnt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dray.Choe\n",
      "IceAmericano\n",
      "JRW\n",
      "Jinyeong\n",
      "Jonggwon\n",
      "Julyeon Seo\n",
      "LSW\n",
      "chico2121\n",
      "cjhan\n",
      "cnuh\n",
      "dhkwak\n",
      "edwin.kang\n",
      "eos73\n",
      "epsilon.kim\n",
      "erin122\n",
      "eunjin\n",
      "hans\n",
      "hexa.ai\n",
      "hihello\n",
      "hihello2\n",
      "hyunji\n",
      "ian.theman\n",
      "jay.mini\n",
      "jihoon.lee\n",
      "jinhyun.b\n",
      "junojuno\n",
      "kwon.g\n",
      "motherfathergentleman\n",
      "robert.p\n",
      "scarlett.heo\n",
      "sungbin.lim\n",
      "wookee3\n",
      "woong.ssang\n",
      "yejun\n",
      "yoomin618\n",
      "score    0.690198\n",
      "dtype: float64 score    0.040811\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "'''user agreement'''\n",
    "user_agree = {'user': [], 'score': []}\n",
    "# for user in l_users:\n",
    "for user in l_filtered_users:    \n",
    "    print(user)\n",
    "    df_answer_person = df_result[df_result['user_id'] == user].sort_values('triplet_id')\n",
    "    l_score = []\n",
    "    for i, row in df_answer_person.iterrows():\n",
    "        triplet_id = row['triplet_id']\n",
    "        if row['answer'] not in (0, 1, 2):\n",
    "            continue\n",
    "\n",
    "        answer = answer_cnt.loc[triplet_id]\n",
    "        o1, o2, o3, p, q = answer['o1'], answer['o2'], answer['o3'], answer['both'], answer['neither']\n",
    "\n",
    "#         o1, o2 = answer['o1'], answer['o2']\n",
    "#         o3 = len(l_users) - o1 - o2\n",
    "\n",
    "        # requires more than two active votes for the triplet\n",
    "        if o1 + o2 < 2:\n",
    "            continue\n",
    "\n",
    "        if row['answer'] in {0, 1}:\n",
    "            if row['answer'] == 0:\n",
    "                oi = o1\n",
    "            else:\n",
    "                oi = o2\n",
    "            s = (oi + 0.5 * p  - 1) / (o1 + o2 + p + q - 1)\n",
    "        elif row['answer'] == 2:\n",
    "            s = (0.5 * o1 + 0.5 * o2 + p - 1 ) / (o1 + o2 + p + q - 1)\n",
    "        else:\n",
    "            s = 0\n",
    "#             s = (q - 1) / (o1 + o2 + p + 1 - 1)\n",
    "        \n",
    "\n",
    "#         s = (o1 + o2 - 1) / (o1 + o2 + o3 - 1) * (oi - 1) / (o1 + o2 - 1)\n",
    "        \n",
    "\n",
    "        l_score.append(s)\n",
    "    score = np.mean(l_score)\n",
    "    user_agree['user'].append(user)\n",
    "    user_agree['score'].append(score)\n",
    "user_agree = pd.DataFrame(user_agree)    \n",
    "user_agree.head()\n",
    "print(user_agree.mean(), user_agree.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agreement between algorithm and human\n",
    "\n",
    "Let  \n",
    "$o1, o2$ : the number of times the first (resp. second) image was chosen.  \n",
    "$p$ : the number of times \"both\" icon were chosen  \n",
    "$q$ : the nubmer of times \"neither\" icon of images were chosen\n",
    "\n",
    "\n",
    "If an algorithm choses the first or the second image, it recieves the following agreement score  \n",
    "$$\n",
    "s = \\frac{o_i + 0.5 p - 1}{o_1 + o_2 + p + q - 1}\n",
    "$$\n",
    "where $o_i$ $i\\in\\{1,2\\}$ is the choice of the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_similarity_data(algo, df_triplet):\n",
    "    '''pre-fetch similarity scores'''\n",
    "    d_sim = {}\n",
    "    result_path = '/data/project/rw/viewer_CBIR/viewer/vg_coco_results/'\n",
    "    for query_id, by_qid in df_triplet.groupby('query_id'):\n",
    "        l_target_ids = list(by_qid['target_id1']) + list(by_qid['target_id2'])\n",
    "        \n",
    "        data = pd.read_csv(os.path.join(result_path, algo, f'{query_id}.tsv'), delimiter='\\t', header=None)\n",
    "        data = data.rename(columns={0:'id', 1:'sim'}).set_index('id')\n",
    "#         sim = data.loc[[int(s) for s in l_target_ids]].to_dict()['sim']\n",
    "        sim = data.reindex([int(s) for s in l_target_ids]).to_dict()['sim']\n",
    "        d_sim[query_id] = sim\n",
    "    return d_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_result(algo, query_id, l_target_ids):\n",
    "    result_path = '/data/project/rw/viewer_CBIR/viewer/vg_coco_results/'\n",
    "    data = pd.read_csv(os.path.join(result_path, algo, f'{query_id}.tsv'), delimiter='\\t', header=None)\n",
    "    data = data.rename(columns={0:'id', 1:'sim'}).set_index('id')\n",
    "    return data.loc[[int(s) for s in l_target_ids]].to_dict()['sim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:06<00:00,  6.52s/it]\n"
     ]
    }
   ],
   "source": [
    "l_algorithms = ['vg_han_tmb_bin_epoch_19']\n",
    "# l_algorithms = ['v1_resnetweight05_epoch_10_rerank', 'gen_v1_resnet07_epoch_99_rerank', 'gen_v1_resnet07_epoch_99']\n",
    "algo_scores = {'triplet_id': list(answer_cnt.index)}\n",
    "d_resnet_sim = read_similarity_data('resnet', df_triplet)\n",
    "for algo in tqdm(l_algorithms):\n",
    "    d_sim_result = read_similarity_data(algo, df_triplet)\n",
    "    l_score = []\n",
    "    for triplet_id, row in answer_cnt.iterrows():\n",
    "        o1, o2, o3, p, q = row['o1'], row['o2'], row['o3'], row['both'], row['neither']\n",
    "\n",
    "        if o1 + o2  < 2:\n",
    "            l_score.append(np.nan)\n",
    "            continue\n",
    "            \n",
    "        # get algorithm's prediction\n",
    "        triplet = df_triplet.loc[triplet_id]\n",
    "        sim1 = d_sim_result[triplet['query_id']][triplet['target_id1']]\n",
    "        sim2 = d_sim_result[triplet['query_id']][triplet['target_id2']]\n",
    "        \n",
    "        # process reranking\n",
    "        if (np.isnan(sim1)) and (np.isnan(sim2)):\n",
    "            sim1 = d_resnet_sim[triplet['query_id']][triplet['target_id1']]\n",
    "            sim2 = d_resnet_sim[triplet['query_id']][triplet['target_id2']]\n",
    "        elif (np.isnan(sim1)) and not (np.isnan(sim2)):\n",
    "            sim1 = - np.inf\n",
    "        elif not (np.isnan(sim1)) and (np.isnan(sim2)):\n",
    "            sim2 = - np.inf\n",
    "        \n",
    "        if sim1 > sim2:\n",
    "            oi = o1\n",
    "        else:\n",
    "            oi = o2\n",
    "        \n",
    "        s = (oi + 0.5 * p ) / (o1 + o2 + p + q )\n",
    "        l_score.append(s)\n",
    "    algo_scores[algo] = l_score\n",
    "algo_scores = pd.DataFrame(algo_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "triplet_id                 4995.389622\n",
       "vg_han_tmb_bin_epoch_19       0.581261\n",
       "dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "triplet_id    4995.389622\n",
       "boo_tfidf        0.593685\n",
       "dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "triplet_id                 4995.389622\n",
       "gwl_rerank                    0.580386\n",
       "gwl_gen_wordonly_rerank       0.590975\n",
       "dtype: float64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo_scores.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
